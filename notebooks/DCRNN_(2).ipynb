{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCRNN (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mi9F4uPc_Gk"
      },
      "source": [
        "The DCRNN Model is referred by [7]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI_c5tz4ZRno",
        "outputId": "73266289-beb5-4b55-faaa-3a92eabd273c"
      },
      "source": [
        "!git clone https://github.com/liyaguang/DCRNN.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DCRNN'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 325 (delta 27), reused 40 (delta 16), pack-reused 272\u001b[K\n",
            "Receiving objects: 100% (325/325), 127.90 MiB | 16.79 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_b0IR8Objgp"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUWjM3TqaPXs",
        "outputId": "9b1df584-d394-47ff-8ba5-c7b663caf7de"
      },
      "source": [
        "%cd /content/DCRNN/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DCRNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrgipJz3Kqcj",
        "outputId": "f1a2ccf7-8308-4da3-b494-9971f7904e20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.10.2)\n",
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.42.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (0.37.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.13.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (3.10.0.2)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->-r requirements.txt (line 5)) (0.5.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0->-r requirements.txt (line 6)) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=00f574839a931731107c391497c7fc586464385305ce0f1ebd8bae35601b8aa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67nyVFWlQC8T",
        "outputId": "b4f4bbfa-a0d7-4ec4-b4a5-5bf41e62ad29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.7.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFRcOdrhahUM"
      },
      "source": [
        "Find, download, and upload the METR-LA and the PEMS-BAY datasets. Download them to your PC first, then upload them onto the session machine to the left. (/content/DCRNN/data/) In my case, I preuploaded the dataset onto Dropbox"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWpFzqsMdmVy",
        "outputId": "72b0d54f-0a7d-4ac8-ee79-c4905d685535"
      },
      "source": [
        "%cd /content/DCRNN/data\n",
        "!wget https://www.dropbox.com/s/3uto6j6zba4kcje/metr-la.h5\n",
        "!wget https://www.dropbox.com/s/akpm0wf7apg6gy0/pems-bay.h5\n",
        "%cd /content/DCRNN/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DCRNN/data\n",
            "--2021-12-27 10:56:22--  https://www.dropbox.com/s/3uto6j6zba4kcje/metr-la.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.68.18, 2620:100:6020:18::a27d:4012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.68.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/3uto6j6zba4kcje/metr-la.h5 [following]\n",
            "--2021-12-27 10:56:22--  https://www.dropbox.com/s/raw/3uto6j6zba4kcje/metr-la.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com/cd/0/inline/BcqfOScOkWMYdusfKhzJ0Ok7Rs-dho1S-YUlsRQEFuTnRHB46YSOSiH_UcAxtKVAr7Aeu_P7uKuYZw4Kh0ICKkuOE8UEf5S-2bWAqwtlgb6ciTmVYmb2u2KP_r2Fasny1qmOswv4ARsjyqdFnMtfYNXS/file# [following]\n",
            "--2021-12-27 10:56:22--  https://uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com/cd/0/inline/BcqfOScOkWMYdusfKhzJ0Ok7Rs-dho1S-YUlsRQEFuTnRHB46YSOSiH_UcAxtKVAr7Aeu_P7uKuYZw4Kh0ICKkuOE8UEf5S-2bWAqwtlgb6ciTmVYmb2u2KP_r2Fasny1qmOswv4ARsjyqdFnMtfYNXS/file\n",
            "Resolving uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com (uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com)... 162.125.68.15, 2620:100:6020:15::a27d:400f\n",
            "Connecting to uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com (uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com)|162.125.68.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bcr4klq4pTZ1IlijYXVxzaxxDG_k7PHZSFa_LtmJdd9lTY3VI29-3tytbUg1f9Eg0NZd4eoHqSg_v5DmpJ9Cw_q6aaLf6jWuBUkQLTBBTrHWuEX2zY6c09yc7XIqw14HWQoNx9cXINnS3KbpSoTiZa2qveh9DjIfO2DL4atu6cc_jctuiSgcuuXcNF9xeCjpXi_xYt5My9UcZ9wpEKun9pGVhMGMcNpuX98J-_rICdUSeOWjYyASIUxfTjv4QVpSrRm9_CznD09gpXDWs5FZxKBnU0jANbPMYC-JYqLNySG7bkqTybUPeH1F4pXUCjzTjo3t_ZBw8QNA0drqcKKnOpV9y5xR32xZ2AsT2wo-nMZ9A7x1B0WlOLU9wja31XJtKjg/file [following]\n",
            "--2021-12-27 10:56:23--  https://uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com/cd/0/inline2/Bcr4klq4pTZ1IlijYXVxzaxxDG_k7PHZSFa_LtmJdd9lTY3VI29-3tytbUg1f9Eg0NZd4eoHqSg_v5DmpJ9Cw_q6aaLf6jWuBUkQLTBBTrHWuEX2zY6c09yc7XIqw14HWQoNx9cXINnS3KbpSoTiZa2qveh9DjIfO2DL4atu6cc_jctuiSgcuuXcNF9xeCjpXi_xYt5My9UcZ9wpEKun9pGVhMGMcNpuX98J-_rICdUSeOWjYyASIUxfTjv4QVpSrRm9_CznD09gpXDWs5FZxKBnU0jANbPMYC-JYqLNySG7bkqTybUPeH1F4pXUCjzTjo3t_ZBw8QNA0drqcKKnOpV9y5xR32xZ2AsT2wo-nMZ9A7x1B0WlOLU9wja31XJtKjg/file\n",
            "Reusing existing connection to uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57038056 (54M) [application/octet-stream]\n",
            "Saving to: ‘metr-la.h5’\n",
            "\n",
            "metr-la.h5          100%[===================>]  54.40M  17.3MB/s    in 3.1s    \n",
            "\n",
            "2021-12-27 10:56:27 (17.3 MB/s) - ‘metr-la.h5’ saved [57038056/57038056]\n",
            "\n",
            "--2021-12-27 10:56:27--  https://www.dropbox.com/s/akpm0wf7apg6gy0/pems-bay.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.68.18, 2620:100:601a:18::a27d:712\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.68.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/akpm0wf7apg6gy0/pems-bay.h5 [following]\n",
            "--2021-12-27 10:56:28--  https://www.dropbox.com/s/raw/akpm0wf7apg6gy0/pems-bay.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com/cd/0/inline/BcreFTZODf9v3tL_HY7GGID9R-YGCn0xy8FJq9axmN36O1g4ubxCSVNYLYkmYyvCmbJAs6PRg-YlK_-9BVzolqL5e_ieOUNkNjnskH9BYgeJFwRK-k9sbxFqrSqeu4N3JoI4MbPWN_DwwI_34KClVdrJ/file# [following]\n",
            "--2021-12-27 10:56:28--  https://ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com/cd/0/inline/BcreFTZODf9v3tL_HY7GGID9R-YGCn0xy8FJq9axmN36O1g4ubxCSVNYLYkmYyvCmbJAs6PRg-YlK_-9BVzolqL5e_ieOUNkNjnskH9BYgeJFwRK-k9sbxFqrSqeu4N3JoI4MbPWN_DwwI_34KClVdrJ/file\n",
            "Resolving ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com (ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com)... 162.125.68.15, 2620:100:6020:15::a27d:400f\n",
            "Connecting to ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com (ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com)|162.125.68.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BcphPqkd3nWZUsqTWpptqMtFDgHUxaxOZDyQ7O9NcYyWuFjVqne6IyEH_S7ysjtSeP8nxqazXRmD4LgmWAys7TXvwMBbo7cyvxfr4Stj2qU_r9hIj_PPUbKCzxo5VSgaydjiJ2EUvb-GxK9bRhO4IGXiMgGSHRnE-wSAdspgZIIIWh6Fp4nnQYaUzV_vUyX7fnLLfd7qwRRHM7VJEkq9gER6XK2P_-Z7QIcsLKEOe7JYf3mOzNENt_1vNXSARJhmcPmsuWT7k5-YWIqSKk3kxg80EPfL82KtAlZ-rDWkbfUljlPHDSa_FS9RGqdXpvj0svyoO6Ulh7y1KYnVlYlVituChu-HM0sexaPJzTvE2v5Nyz_Dyo7Ji6t1jcD4ccmUgYM/file [following]\n",
            "--2021-12-27 10:56:29--  https://ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com/cd/0/inline2/BcphPqkd3nWZUsqTWpptqMtFDgHUxaxOZDyQ7O9NcYyWuFjVqne6IyEH_S7ysjtSeP8nxqazXRmD4LgmWAys7TXvwMBbo7cyvxfr4Stj2qU_r9hIj_PPUbKCzxo5VSgaydjiJ2EUvb-GxK9bRhO4IGXiMgGSHRnE-wSAdspgZIIIWh6Fp4nnQYaUzV_vUyX7fnLLfd7qwRRHM7VJEkq9gER6XK2P_-Z7QIcsLKEOe7JYf3mOzNENt_1vNXSARJhmcPmsuWT7k5-YWIqSKk3kxg80EPfL82KtAlZ-rDWkbfUljlPHDSa_FS9RGqdXpvj0svyoO6Ulh7y1KYnVlYlVituChu-HM0sexaPJzTvE2v5Nyz_Dyo7Ji6t1jcD4ccmUgYM/file\n",
            "Reusing existing connection to ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 135930936 (130M) [application/octet-stream]\n",
            "Saving to: ‘pems-bay.h5’\n",
            "\n",
            "pems-bay.h5         100%[===================>] 129.63M  15.7MB/s    in 8.9s    \n",
            "\n",
            "2021-12-27 10:56:39 (14.6 MB/s) - ‘pems-bay.h5’ saved [135930936/135930936]\n",
            "\n",
            "/content/DCRNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before processing the data, make sure that the downloaded files are in the \"data\" folder by opening the file explorer tab to the left. If not, move them in."
      ],
      "metadata": {
        "id": "7H-_K-hpQxCk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZhZvq47ago5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb20aca-8539-429a-8695-7f35997ff2ea"
      },
      "source": [
        "%mkdir -p data/{METR-LA,PEMS-BAY}\n",
        "\n",
        "# METR-LA\n",
        "!python -m scripts.generate_training_data --output_dir=data/METR-LA --traffic_df_filename=data/metr-la.h5\n",
        "\n",
        "# PEMS-BAY\n",
        "!python -m scripts.generate_training_data --output_dir=data/PEMS-BAY --traffic_df_filename=data/pems-bay.h5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data\n",
            "tcmalloc: large alloc 1361199104 bytes == 0x55e696f3e000 @  0x7fbb11b6c1e7 0x7fbb0f66c46e 0x7fbb0f6bcc7b 0x7fbb0f6bcd18 0x7fbb0f764010 0x7fbb0f76473c 0x7fbb0f76485d 0x55e5defde749 0x7fbb0f6a9ef7 0x55e5defdc437 0x55e5defdc240 0x55e5df04f973 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5df04aced 0x55e5def1ce2b 0x7fbb0f6a9ef7 0x55e5defdc437 0x55e5defdc240 0x55e5df04f973 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5defddafa 0x55e5df04b915 0x55e5defddafa 0x55e5df04b915\n",
            "tcmalloc: large alloc 1361199104 bytes == 0x55e6e89e2000 @  0x7fbb11b6c1e7 0x7fbb0f66c46e 0x7fbb0f6bcc7b 0x7fbb0f6bcd18 0x7fbb0f764010 0x7fbb0f76473c 0x7fbb0f76485d 0x55e5defde749 0x7fbb0f6a9ef7 0x55e5defdc437 0x55e5defdc240 0x55e5df04f973 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5df04aced 0x55e5def1ce2b 0x7fbb0f6a9ef7 0x55e5defdc437 0x55e5defdc240 0x55e5df04f973 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5defddafa 0x55e5df04b915 0x55e5defddafa 0x55e5df04b915\n",
            "x shape:  (34249, 12, 207, 2) , y shape:  (34249, 12, 207, 2)\n",
            "train x:  (23974, 12, 207, 2) y: (23974, 12, 207, 2)\n",
            "val x:  (3425, 12, 207, 2) y: (3425, 12, 207, 2)\n",
            "test x:  (6850, 12, 207, 2) y: (6850, 12, 207, 2)\n",
            "Generating training data\n",
            "tcmalloc: large alloc 3250610176 bytes == 0x55da330fc000 @  0x7fe250cdf1e7 0x7fe24e81f46e 0x7fe24e86fc7b 0x7fe24e86fd18 0x7fe24e917010 0x7fe24e91773c 0x7fe24e91785d 0x55d877361749 0x7fe24e85cef7 0x55d87735f437 0x55d87735f240 0x55d8773d2973 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d8773cdced 0x55d87729fe2b 0x7fe24e85cef7 0x55d87735f437 0x55d87735f240 0x55d8773d2973 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d877360afa 0x55d8773ce915 0x55d877360afa 0x55d8773ce915\n",
            "tcmalloc: large alloc 3250610176 bytes == 0x55daf559c000 @  0x7fe250cdf1e7 0x7fe24e81f46e 0x7fe24e86fc7b 0x7fe24e86fd18 0x7fe24e917010 0x7fe24e91773c 0x7fe24e91785d 0x55d877361749 0x7fe24e85cef7 0x55d87735f437 0x55d87735f240 0x55d8773d2973 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d8773cdced 0x55d87729fe2b 0x7fe24e85cef7 0x55d87735f437 0x55d87735f240 0x55d8773d2973 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d877360afa 0x55d8773ce915 0x55d877360afa 0x55d8773ce915\n",
            "x shape:  (52093, 12, 325, 2) , y shape:  (52093, 12, 325, 2)\n",
            "train x:  (36465, 12, 325, 2) y: (36465, 12, 325, 2)\n",
            "val x:  (5209, 12, 325, 2) y: (5209, 12, 325, 2)\n",
            "test x:  (10419, 12, 325, 2) y: (10419, 12, 325, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRG1zTVCboer"
      },
      "source": [
        "After the datasets are loaded, construct a graph as an input for the GCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN_jAqL8aU2h"
      },
      "source": [
        "!python -m scripts.gen_adj_mx  --sensor_ids_filename=data/sensor_graph/graph_sensor_ids.txt --normalized_k=0.1\\\n",
        "    --output_pkl_filename=data/sensor_graph/adj_mx.pkl"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uBgXAQrcIE4"
      },
      "source": [
        "Run the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTJeSkrzcKic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0622959c-d883-4c1e-dbe1-280fb1367d35"
      },
      "source": [
        "# METR-LA\n",
        "!python run_demo.py --config_filename=data/model/pretrained/METR-LA/config.yaml\n",
        "\n",
        "# PEMS-BAY\n",
        "!python run_demo.py --config_filename=data/model/pretrained/PEMS-BAY/config.yaml\n",
        "#The generated prediction of DCRNN is in data/results/dcrnn_predictions."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From run_demo.py:15: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From run_demo.py:21: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-12-27 11:06:41.028143: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-12-27 11:06:41.033464: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-12-27 11:06:41.033694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564fdec55100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-27 11:06:41.033731: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-12-27 11:06:41.048324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-27 11:06:41.216905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:06:41.217869: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564fe3beec40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-27 11:06:41.217903: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-12-27 11:06:41.218375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:06:41.219150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-12-27 11:06:41.262009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-12-27 11:06:41.431333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-12-27 11:06:41.507953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-12-27 11:06:41.532474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-12-27 11:06:41.695870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-12-27 11:06:41.797762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-12-27 11:06:42.152333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-12-27 11:06:42.152563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:06:42.153369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:06:42.154173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-12-27 11:06:42.154271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-12-27 11:06:42.156030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-12-27 11:06:42.156104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-12-27 11:06:42.156137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-12-27 11:06:42.156305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:06:42.157252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:06:42.158000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-12-27 11:06:42,159 - INFO - Log directory: data/model/pretrained/METR-LA\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:35: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "2021-12-27 11:06:42,160 - INFO - {'base_dir': 'data/model', 'log_level': 'INFO', 'data': {'batch_size': 64, 'dataset_dir': 'data/METR-LA', 'graph_pkl_filename': 'data/sensor_graph/adj_mx.pkl', 'test_batch_size': 64}, 'model': {'cl_decay_steps': 2000, 'filter_type': 'dual_random_walk', 'horizon': 12, 'input_dim': 2, 'l1_decay': 0, 'max_diffusion_step': 2, 'num_nodes': 207, 'num_rnn_layers': 2, 'output_dim': 1, 'rnn_units': 64, 'seq_len': 12, 'use_curriculum_learning': True}, 'train': {'base_lr': 0.01, 'dropout': 0, 'epoch': 64, 'epochs': 100, 'epsilon': 0.001, 'global_step': 24375, 'log_dir': 'data/model/pretrained/METR-LA', 'lr_decay_ratio': 0.1, 'max_grad_norm': 5, 'max_to_keep': 100, 'min_learning_rate': 2e-06, 'model_filename': 'data/model/pretrained/METR-LA/models-2.7422-24375', 'optimizer': 'adam', 'patience': 50, 'steps': [20, 30, 40, 50], 'test_every_n_epochs': 10}}\n",
            "2021-12-27 11:06:58,623 - INFO - ('x_train', (23974, 12, 207, 2))\n",
            "2021-12-27 11:06:58,623 - INFO - ('y_train', (23974, 12, 207, 2))\n",
            "2021-12-27 11:06:58,623 - INFO - ('x_val', (3425, 12, 207, 2))\n",
            "2021-12-27 11:06:58,623 - INFO - ('y_val', (3425, 12, 207, 2))\n",
            "2021-12-27 11:06:58,623 - INFO - ('x_test', (6850, 12, 207, 2))\n",
            "2021-12-27 11:06:58,623 - INFO - ('y_test', (6850, 12, 207, 2))\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:47: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_model.py:37: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_cell.py:64: The name tf.sparse_reorder is deprecated. Please use tf.sparse.reorder instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_model.py:50: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_model.py:53: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_model.py:75: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_cell.py:156: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_cell.py:162: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_cell.py:175: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_cell.py:181: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_model.py:65: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_model.py:82: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:62: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:67: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/lib/metrics.py:40: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/lib/metrics.py:40: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:82: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:91: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:91: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "2021-12-27 11:07:17,752 - INFO - Total number of trainable parameters: 372352\n",
            "2021-12-27 11:07:22.337509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "WARNING:tensorflow:From /content/DCRNN/lib/utils.py:78: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "2021-12-27 11:09:11,258 - INFO - Horizon 01, MAE: 2.17, MAPE: 0.0517, RMSE: 3.76\n",
            "2021-12-27 11:09:11,412 - INFO - Horizon 02, MAE: 2.47, MAPE: 0.0612, RMSE: 4.59\n",
            "2021-12-27 11:09:11,564 - INFO - Horizon 03, MAE: 2.66, MAPE: 0.0683, RMSE: 5.16\n",
            "2021-12-27 11:09:11,716 - INFO - Horizon 04, MAE: 2.82, MAPE: 0.0742, RMSE: 5.61\n",
            "2021-12-27 11:09:11,862 - INFO - Horizon 05, MAE: 2.95, MAPE: 0.0792, RMSE: 5.98\n",
            "2021-12-27 11:09:12,011 - INFO - Horizon 06, MAE: 3.06, MAPE: 0.0836, RMSE: 6.28\n",
            "2021-12-27 11:09:12,157 - INFO - Horizon 07, MAE: 3.16, MAPE: 0.0875, RMSE: 6.54\n",
            "2021-12-27 11:09:12,303 - INFO - Horizon 08, MAE: 3.25, MAPE: 0.0910, RMSE: 6.77\n",
            "2021-12-27 11:09:12,435 - INFO - Horizon 09, MAE: 3.33, MAPE: 0.0941, RMSE: 6.97\n",
            "2021-12-27 11:09:12,569 - INFO - Horizon 10, MAE: 3.40, MAPE: 0.0970, RMSE: 7.15\n",
            "2021-12-27 11:09:12,695 - INFO - Horizon 11, MAE: 3.47, MAPE: 0.0996, RMSE: 7.31\n",
            "2021-12-27 11:09:12,818 - INFO - Horizon 12, MAE: 3.54, MAPE: 0.1024, RMSE: 7.48\n",
            "Predictions saved as data/dcrnn_predictions.npz.\n",
            "WARNING:tensorflow:From run_demo.py:15: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From run_demo.py:21: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-12-27 11:09:30.976917: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-12-27 11:09:30.982415: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-12-27 11:09:30.982651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5566eb657100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-27 11:09:30.982700: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-12-27 11:09:30.984477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-27 11:09:31.093965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:09:31.094922: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5566eb657640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-27 11:09:31.094958: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-12-27 11:09:31.095184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:09:31.095886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-12-27 11:09:31.096273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-12-27 11:09:31.097727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-12-27 11:09:31.099104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-12-27 11:09:31.099497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-12-27 11:09:31.107544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-12-27 11:09:31.108849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-12-27 11:09:31.113600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-12-27 11:09:31.113725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:09:31.114565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:09:31.115396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-12-27 11:09:31.115468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-12-27 11:09:31.116896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-12-27 11:09:31.116929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-12-27 11:09:31.116947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-12-27 11:09:31.117120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:09:31.117898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:09:31.118641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-12-27 11:09:31,120 - INFO - Log directory: data/model/pretrained/PEMS-BAY/\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:35: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "2021-12-27 11:09:31,121 - INFO - {'base_dir': 'data/model', 'data': {'batch_size': 64, 'dataset_dir': 'data/PEMS-BAY', 'graph_pkl_filename': 'data/sensor_graph/adj_mx_bay.pkl', 'test_batch_size': 64, 'val_batch_size': 64}, 'log_level': 'INFO', 'model': {'cl_decay_steps': 2000, 'filter_type': 'dual_random_walk', 'horizon': 12, 'input_dim': 2, 'l1_decay': 0, 'max_diffusion_step': 2, 'num_nodes': 325, 'num_rnn_layers': 2, 'output_dim': 1, 'rnn_units': 64, 'seq_len': 12, 'use_curriculum_learning': True}, 'train': {'base_lr': 0.01, 'dropout': 0, 'epoch': 53, 'epochs': 100, 'epsilon': 0.001, 'global_step': 30780, 'log_dir': 'data/model/pretrained/PEMS-BAY/', 'lr_decay_ratio': 0.1, 'max_grad_norm': 5, 'max_to_keep': 100, 'min_learning_rate': 2e-06, 'model_filename': 'data/model/pretrained/PEMS-BAY/models-1.6139-30780', 'optimizer': 'adam', 'patience': 50, 'steps': [20, 30, 40, 50], 'test_every_n_epochs': 10}}\n",
            "tcmalloc: large alloc 2275418112 bytes == 0x5566f0b9a000 @  0x7fd85a9bd1e7 0x7fd85853d46e 0x7fd85858dc7b 0x7fd858540ce8 0x5566ea2c0045 0x5566ea280d49 0x5566ea2f494f 0x5566ea2ee9ee 0x5566ea281bda 0x5566ea2f0737 0x5566ea283b6b 0x5566ea2c49c9 0x5566ea2c493c 0x5566ea368409 0x5566ea2efe7a 0x5566ea2ee9ee 0x5566ea1c0e2b 0x5566ea2f0fe4 0x5566ea2ee9ee 0x5566ea28248c 0x5566ea2c3159 0x5566ea2c00a4 0x5566ea282698 0x5566ea2f0fe4 0x5566ea281afa 0x5566ea2ef915 0x5566ea2ee9ee 0x5566ea2ee6f3 0x5566ea3b84c2 0x5566ea3b883d 0x5566ea3b86e6\n",
            "tcmalloc: large alloc 2275418112 bytes == 0x556778864000 @  0x7fd85a9bd1e7 0x7fd85853d46e 0x7fd85858dc7b 0x7fd858540ce8 0x5566ea2c0045 0x5566ea280d49 0x5566ea2f494f 0x5566ea2ee9ee 0x5566ea281bda 0x5566ea2f0737 0x5566ea283b6b 0x5566ea2c49c9 0x5566ea2c493c 0x5566ea368409 0x5566ea2efe7a 0x5566ea2ee9ee 0x5566ea1c0e2b 0x5566ea2f0fe4 0x5566ea2ee9ee 0x5566ea28248c 0x5566ea2c3159 0x5566ea2c00a4 0x5566ea282698 0x5566ea2f0fe4 0x5566ea281afa 0x5566ea2ef915 0x5566ea2ee9ee 0x5566ea2ee6f3 0x5566ea3b84c2 0x5566ea3b883d 0x5566ea3b86e6\n",
            "tcmalloc: large alloc 2276352000 bytes == 0x5568b8cc8000 @  0x7fd85a9bd1e7 0x7fd85853d46e 0x7fd85858dc7b 0x7fd85858dd18 0x7fd858635010 0x7fd85863573c 0x7fd85863585d 0x5566ea282749 0x7fd85857aef7 0x5566ea280437 0x5566ea280240 0x5566ea2f3973 0x5566ea2ee9ee 0x5566ea281bda 0x5566ea2f0737 0x5566ea2ee9ee 0x5566ea28248c 0x5566ea2c3159 0x5566ea2c00a4 0x5566ea280d49 0x5566ea2f494f 0x5566ea2ee9ee 0x5566ea1c0e2b 0x5566ea2f0fe4 0x5566ea2ee9ee 0x5566ea28248c 0x5566ea2c3159 0x5566ea2c00a4 0x5566ea282698 0x5566ea2f0fe4 0x5566ea281afa\n",
            "tcmalloc: large alloc 2276352000 bytes == 0x5569407ae000 @  0x7fd85a9bd1e7 0x7fd85853d46e 0x7fd85858dc7b 0x7fd85858dd18 0x7fd858635010 0x7fd85863573c 0x7fd85863585d 0x5566ea282749 0x7fd85857aef7 0x5566ea280437 0x5566ea280240 0x5566ea2f3973 0x5566ea2ee9ee 0x5566ea281bda 0x5566ea2f0737 0x5566ea2ee9ee 0x5566ea28248c 0x5566ea2c3159 0x5566ea2c00a4 0x5566ea280d49 0x5566ea2f494f 0x5566ea2ee9ee 0x5566ea1c0e2b 0x5566ea2f0fe4 0x5566ea2ee9ee 0x5566ea28248c 0x5566ea2c3159 0x5566ea2c00a4 0x5566ea282698 0x5566ea2f0fe4 0x5566ea281afa\n",
            "tcmalloc: large alloc 2276352000 bytes == 0x5569c8294000 @  0x7fd85a9bd1e7 0x7fd85853d46e 0x7fd85858dc7b 0x7fd85858dd18 0x7fd8586203a9 0x7fd858622ab5 0x5566ea368409 0x5566ea2efe7a 0x5566ea2ee9ee 0x5566ea28248c 0x5566ea2c3159 0x5566ea2c00a4 0x5566ea280d49 0x5566ea2f494f 0x5566ea2ee9ee 0x5566ea1c0e2b 0x5566ea2f0fe4 0x5566ea2ee9ee 0x5566ea28248c 0x5566ea2c3159 0x5566ea2c00a4 0x5566ea282698 0x5566ea2f0fe4 0x5566ea281afa 0x5566ea2ef915 0x5566ea2ee9ee 0x5566ea2ee6f3 0x5566ea3b84c2 0x5566ea3b883d 0x5566ea3b86e6 0x5566ea390163\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SJybBDWcM8G"
      },
      "source": [
        "Or retrain the model completely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3RKvlPecRCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c01ee5-b4ad-4d7a-8f14-9947854828ab"
      },
      "source": [
        "# METR-LA\n",
        "!python dcrnn_train.py --config_filename=data/model/dcrnn_la.yaml\n",
        "\n",
        "# PEMS-BAY\n",
        "!python dcrnn_train.py --config_filename=data/model/dcrnn_bay.yaml"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"dcrnn_train.py\", line 10, in <module>\n",
            "    from model.dcrnn_supervisor import DCRNNSupervisor\n",
            "  File \"/content/DCRNN/model/dcrnn_supervisor.py\", line 16, in <module>\n",
            "    from model.dcrnn_model import DCRNNModel\n",
            "  File \"/content/DCRNN/model/dcrnn_model.py\", line 7, in <module>\n",
            "    from tensorflow.contrib import legacy_seq2seq\n",
            "ModuleNotFoundError: No module named 'tensorflow.contrib'\n",
            "Traceback (most recent call last):\n",
            "  File \"dcrnn_train.py\", line 10, in <module>\n",
            "    from model.dcrnn_supervisor import DCRNNSupervisor\n",
            "  File \"/content/DCRNN/model/dcrnn_supervisor.py\", line 16, in <module>\n",
            "    from model.dcrnn_model import DCRNNModel\n",
            "  File \"/content/DCRNN/model/dcrnn_model.py\", line 7, in <module>\n",
            "    from tensorflow.contrib import legacy_seq2seq\n",
            "ModuleNotFoundError: No module named 'tensorflow.contrib'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeRyGzjdchZh"
      },
      "source": [
        "Eval Baseline Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKzLUzKOcjVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d279033b-b092-49cb-a6ed-a6b882b4ffe7"
      },
      "source": [
        "# METR-LA\n",
        "!python -m scripts.eval_baseline_methods --traffic_reading_filename=data/metr-la.h5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "2021-12-27 11:03:24,786 - INFO - Log directory: data/model\n",
            "2021-12-27 11:03:25,064 - INFO - Static\n",
            "2021-12-27 11:03:25,064 - INFO - Model\tHorizon\tRMSE\tMAPE\tMAE\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DCRNN/scripts/eval_baseline_methods.py\", line 141, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DCRNN/scripts/eval_baseline_methods.py\", line 130, in main\n",
            "    eval_static(traffic_reading_df)\n",
            "  File \"/content/DCRNN/scripts/eval_baseline_methods.py\", line 95, in eval_static\n",
            "    rmse = masked_rmse_np(preds=y_predict.as_matrix(), labels=y_test.as_matrix(), null_val=0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\", line 5141, in __getattr__\n",
            "    return object.__getattribute__(self, name)\n",
            "AttributeError: 'DataFrame' object has no attribute 'as_matrix'\n"
          ]
        }
      ]
    }
  ]
}