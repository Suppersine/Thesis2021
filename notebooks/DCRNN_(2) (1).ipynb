{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCRNN (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mi9F4uPc_Gk"
      },
      "source": [
        "The DCRNN Model is referred by [7]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI_c5tz4ZRno",
        "outputId": "73266289-beb5-4b55-faaa-3a92eabd273c"
      },
      "source": [
        "!git clone https://github.com/liyaguang/DCRNN.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DCRNN'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 325 (delta 27), reused 40 (delta 16), pack-reused 272\u001b[K\n",
            "Receiving objects: 100% (325/325), 127.90 MiB | 16.79 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_b0IR8Objgp"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUWjM3TqaPXs",
        "outputId": "9b1df584-d394-47ff-8ba5-c7b663caf7de"
      },
      "source": [
        "%cd /content/DCRNN/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DCRNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrgipJz3Kqcj",
        "outputId": "f1a2ccf7-8308-4da3-b494-9971f7904e20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.10.2)\n",
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.42.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (0.37.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.13.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0->-r requirements.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0->-r requirements.txt (line 6)) (3.10.0.2)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->-r requirements.txt (line 5)) (0.5.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0->-r requirements.txt (line 6)) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=00f574839a931731107c391497c7fc586464385305ce0f1ebd8bae35601b8aa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67nyVFWlQC8T",
        "outputId": "b4f4bbfa-a0d7-4ec4-b4a5-5bf41e62ad29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.7.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFRcOdrhahUM"
      },
      "source": [
        "Find, download, and upload the METR-LA and the PEMS-BAY datasets. Download them to your PC first, then upload them onto the session machine to the left. (/content/DCRNN/data/) In my case, I preuploaded the dataset onto Dropbox"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWpFzqsMdmVy",
        "outputId": "72b0d54f-0a7d-4ac8-ee79-c4905d685535"
      },
      "source": [
        "%cd /content/DCRNN/data\n",
        "!wget https://www.dropbox.com/s/3uto6j6zba4kcje/metr-la.h5\n",
        "!wget https://www.dropbox.com/s/akpm0wf7apg6gy0/pems-bay.h5\n",
        "%cd /content/DCRNN/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DCRNN/data\n",
            "--2021-12-27 10:56:22--  https://www.dropbox.com/s/3uto6j6zba4kcje/metr-la.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.68.18, 2620:100:6020:18::a27d:4012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.68.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/3uto6j6zba4kcje/metr-la.h5 [following]\n",
            "--2021-12-27 10:56:22--  https://www.dropbox.com/s/raw/3uto6j6zba4kcje/metr-la.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com/cd/0/inline/BcqfOScOkWMYdusfKhzJ0Ok7Rs-dho1S-YUlsRQEFuTnRHB46YSOSiH_UcAxtKVAr7Aeu_P7uKuYZw4Kh0ICKkuOE8UEf5S-2bWAqwtlgb6ciTmVYmb2u2KP_r2Fasny1qmOswv4ARsjyqdFnMtfYNXS/file# [following]\n",
            "--2021-12-27 10:56:22--  https://uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com/cd/0/inline/BcqfOScOkWMYdusfKhzJ0Ok7Rs-dho1S-YUlsRQEFuTnRHB46YSOSiH_UcAxtKVAr7Aeu_P7uKuYZw4Kh0ICKkuOE8UEf5S-2bWAqwtlgb6ciTmVYmb2u2KP_r2Fasny1qmOswv4ARsjyqdFnMtfYNXS/file\n",
            "Resolving uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com (uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com)... 162.125.68.15, 2620:100:6020:15::a27d:400f\n",
            "Connecting to uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com (uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com)|162.125.68.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bcr4klq4pTZ1IlijYXVxzaxxDG_k7PHZSFa_LtmJdd9lTY3VI29-3tytbUg1f9Eg0NZd4eoHqSg_v5DmpJ9Cw_q6aaLf6jWuBUkQLTBBTrHWuEX2zY6c09yc7XIqw14HWQoNx9cXINnS3KbpSoTiZa2qveh9DjIfO2DL4atu6cc_jctuiSgcuuXcNF9xeCjpXi_xYt5My9UcZ9wpEKun9pGVhMGMcNpuX98J-_rICdUSeOWjYyASIUxfTjv4QVpSrRm9_CznD09gpXDWs5FZxKBnU0jANbPMYC-JYqLNySG7bkqTybUPeH1F4pXUCjzTjo3t_ZBw8QNA0drqcKKnOpV9y5xR32xZ2AsT2wo-nMZ9A7x1B0WlOLU9wja31XJtKjg/file [following]\n",
            "--2021-12-27 10:56:23--  https://uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com/cd/0/inline2/Bcr4klq4pTZ1IlijYXVxzaxxDG_k7PHZSFa_LtmJdd9lTY3VI29-3tytbUg1f9Eg0NZd4eoHqSg_v5DmpJ9Cw_q6aaLf6jWuBUkQLTBBTrHWuEX2zY6c09yc7XIqw14HWQoNx9cXINnS3KbpSoTiZa2qveh9DjIfO2DL4atu6cc_jctuiSgcuuXcNF9xeCjpXi_xYt5My9UcZ9wpEKun9pGVhMGMcNpuX98J-_rICdUSeOWjYyASIUxfTjv4QVpSrRm9_CznD09gpXDWs5FZxKBnU0jANbPMYC-JYqLNySG7bkqTybUPeH1F4pXUCjzTjo3t_ZBw8QNA0drqcKKnOpV9y5xR32xZ2AsT2wo-nMZ9A7x1B0WlOLU9wja31XJtKjg/file\n",
            "Reusing existing connection to uc0eb41b9ba8d7b219b2e062d9e9.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57038056 (54M) [application/octet-stream]\n",
            "Saving to: ‘metr-la.h5’\n",
            "\n",
            "metr-la.h5          100%[===================>]  54.40M  17.3MB/s    in 3.1s    \n",
            "\n",
            "2021-12-27 10:56:27 (17.3 MB/s) - ‘metr-la.h5’ saved [57038056/57038056]\n",
            "\n",
            "--2021-12-27 10:56:27--  https://www.dropbox.com/s/akpm0wf7apg6gy0/pems-bay.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.68.18, 2620:100:601a:18::a27d:712\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.68.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/akpm0wf7apg6gy0/pems-bay.h5 [following]\n",
            "--2021-12-27 10:56:28--  https://www.dropbox.com/s/raw/akpm0wf7apg6gy0/pems-bay.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com/cd/0/inline/BcreFTZODf9v3tL_HY7GGID9R-YGCn0xy8FJq9axmN36O1g4ubxCSVNYLYkmYyvCmbJAs6PRg-YlK_-9BVzolqL5e_ieOUNkNjnskH9BYgeJFwRK-k9sbxFqrSqeu4N3JoI4MbPWN_DwwI_34KClVdrJ/file# [following]\n",
            "--2021-12-27 10:56:28--  https://ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com/cd/0/inline/BcreFTZODf9v3tL_HY7GGID9R-YGCn0xy8FJq9axmN36O1g4ubxCSVNYLYkmYyvCmbJAs6PRg-YlK_-9BVzolqL5e_ieOUNkNjnskH9BYgeJFwRK-k9sbxFqrSqeu4N3JoI4MbPWN_DwwI_34KClVdrJ/file\n",
            "Resolving ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com (ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com)... 162.125.68.15, 2620:100:6020:15::a27d:400f\n",
            "Connecting to ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com (ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com)|162.125.68.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BcphPqkd3nWZUsqTWpptqMtFDgHUxaxOZDyQ7O9NcYyWuFjVqne6IyEH_S7ysjtSeP8nxqazXRmD4LgmWAys7TXvwMBbo7cyvxfr4Stj2qU_r9hIj_PPUbKCzxo5VSgaydjiJ2EUvb-GxK9bRhO4IGXiMgGSHRnE-wSAdspgZIIIWh6Fp4nnQYaUzV_vUyX7fnLLfd7qwRRHM7VJEkq9gER6XK2P_-Z7QIcsLKEOe7JYf3mOzNENt_1vNXSARJhmcPmsuWT7k5-YWIqSKk3kxg80EPfL82KtAlZ-rDWkbfUljlPHDSa_FS9RGqdXpvj0svyoO6Ulh7y1KYnVlYlVituChu-HM0sexaPJzTvE2v5Nyz_Dyo7Ji6t1jcD4ccmUgYM/file [following]\n",
            "--2021-12-27 10:56:29--  https://ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com/cd/0/inline2/BcphPqkd3nWZUsqTWpptqMtFDgHUxaxOZDyQ7O9NcYyWuFjVqne6IyEH_S7ysjtSeP8nxqazXRmD4LgmWAys7TXvwMBbo7cyvxfr4Stj2qU_r9hIj_PPUbKCzxo5VSgaydjiJ2EUvb-GxK9bRhO4IGXiMgGSHRnE-wSAdspgZIIIWh6Fp4nnQYaUzV_vUyX7fnLLfd7qwRRHM7VJEkq9gER6XK2P_-Z7QIcsLKEOe7JYf3mOzNENt_1vNXSARJhmcPmsuWT7k5-YWIqSKk3kxg80EPfL82KtAlZ-rDWkbfUljlPHDSa_FS9RGqdXpvj0svyoO6Ulh7y1KYnVlYlVituChu-HM0sexaPJzTvE2v5Nyz_Dyo7Ji6t1jcD4ccmUgYM/file\n",
            "Reusing existing connection to ucb1905dfcfdcda0c844222a8f69.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 135930936 (130M) [application/octet-stream]\n",
            "Saving to: ‘pems-bay.h5’\n",
            "\n",
            "pems-bay.h5         100%[===================>] 129.63M  15.7MB/s    in 8.9s    \n",
            "\n",
            "2021-12-27 10:56:39 (14.6 MB/s) - ‘pems-bay.h5’ saved [135930936/135930936]\n",
            "\n",
            "/content/DCRNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before processing the data, make sure that the downloaded files are in the \"data\" folder by opening the file explorer tab to the left. If not, move them in."
      ],
      "metadata": {
        "id": "7H-_K-hpQxCk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZhZvq47ago5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb20aca-8539-429a-8695-7f35997ff2ea"
      },
      "source": [
        "%mkdir -p data/{METR-LA,PEMS-BAY}\n",
        "\n",
        "# METR-LA\n",
        "!python -m scripts.generate_training_data --output_dir=data/METR-LA --traffic_df_filename=data/metr-la.h5\n",
        "\n",
        "# PEMS-BAY\n",
        "!python -m scripts.generate_training_data --output_dir=data/PEMS-BAY --traffic_df_filename=data/pems-bay.h5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data\n",
            "tcmalloc: large alloc 1361199104 bytes == 0x55e696f3e000 @  0x7fbb11b6c1e7 0x7fbb0f66c46e 0x7fbb0f6bcc7b 0x7fbb0f6bcd18 0x7fbb0f764010 0x7fbb0f76473c 0x7fbb0f76485d 0x55e5defde749 0x7fbb0f6a9ef7 0x55e5defdc437 0x55e5defdc240 0x55e5df04f973 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5df04aced 0x55e5def1ce2b 0x7fbb0f6a9ef7 0x55e5defdc437 0x55e5defdc240 0x55e5df04f973 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5defddafa 0x55e5df04b915 0x55e5defddafa 0x55e5df04b915\n",
            "tcmalloc: large alloc 1361199104 bytes == 0x55e6e89e2000 @  0x7fbb11b6c1e7 0x7fbb0f66c46e 0x7fbb0f6bcc7b 0x7fbb0f6bcd18 0x7fbb0f764010 0x7fbb0f76473c 0x7fbb0f76485d 0x55e5defde749 0x7fbb0f6a9ef7 0x55e5defdc437 0x55e5defdc240 0x55e5df04f973 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5df04aced 0x55e5def1ce2b 0x7fbb0f6a9ef7 0x55e5defdc437 0x55e5defdc240 0x55e5df04f973 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5df04a9ee 0x55e5defddbda 0x55e5df04c737 0x55e5defddafa 0x55e5df04b915 0x55e5defddafa 0x55e5df04b915\n",
            "x shape:  (34249, 12, 207, 2) , y shape:  (34249, 12, 207, 2)\n",
            "train x:  (23974, 12, 207, 2) y: (23974, 12, 207, 2)\n",
            "val x:  (3425, 12, 207, 2) y: (3425, 12, 207, 2)\n",
            "test x:  (6850, 12, 207, 2) y: (6850, 12, 207, 2)\n",
            "Generating training data\n",
            "tcmalloc: large alloc 3250610176 bytes == 0x55da330fc000 @  0x7fe250cdf1e7 0x7fe24e81f46e 0x7fe24e86fc7b 0x7fe24e86fd18 0x7fe24e917010 0x7fe24e91773c 0x7fe24e91785d 0x55d877361749 0x7fe24e85cef7 0x55d87735f437 0x55d87735f240 0x55d8773d2973 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d8773cdced 0x55d87729fe2b 0x7fe24e85cef7 0x55d87735f437 0x55d87735f240 0x55d8773d2973 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d877360afa 0x55d8773ce915 0x55d877360afa 0x55d8773ce915\n",
            "tcmalloc: large alloc 3250610176 bytes == 0x55daf559c000 @  0x7fe250cdf1e7 0x7fe24e81f46e 0x7fe24e86fc7b 0x7fe24e86fd18 0x7fe24e917010 0x7fe24e91773c 0x7fe24e91785d 0x55d877361749 0x7fe24e85cef7 0x55d87735f437 0x55d87735f240 0x55d8773d2973 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d8773cdced 0x55d87729fe2b 0x7fe24e85cef7 0x55d87735f437 0x55d87735f240 0x55d8773d2973 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d8773cd9ee 0x55d877360bda 0x55d8773cf737 0x55d877360afa 0x55d8773ce915 0x55d877360afa 0x55d8773ce915\n",
            "x shape:  (52093, 12, 325, 2) , y shape:  (52093, 12, 325, 2)\n",
            "train x:  (36465, 12, 325, 2) y: (36465, 12, 325, 2)\n",
            "val x:  (5209, 12, 325, 2) y: (5209, 12, 325, 2)\n",
            "test x:  (10419, 12, 325, 2) y: (10419, 12, 325, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRG1zTVCboer"
      },
      "source": [
        "After the datasets are loaded, construct a graph as an input for the GCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN_jAqL8aU2h"
      },
      "source": [
        "!python -m scripts.gen_adj_mx  --sensor_ids_filename=data/sensor_graph/graph_sensor_ids.txt --normalized_k=0.1\\\n",
        "    --output_pkl_filename=data/sensor_graph/adj_mx.pkl"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uBgXAQrcIE4"
      },
      "source": [
        "Run the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTJeSkrzcKic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbac97b3-3dc0-4995-cde9-6d2effb18581"
      },
      "source": [
        "# METR-LA\n",
        "!python run_demo.py --config_filename=data/model/pretrained/METR-LA/config.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From run_demo.py:15: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From run_demo.py:21: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-12-27 11:12:50.134534: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-12-27 11:12:50.151572: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-12-27 11:12:50.153653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558be126b100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-27 11:12:50.153687: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-12-27 11:12:50.167594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-27 11:12:50.345493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:12:50.346536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558be6204c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-12-27 11:12:50.346585: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-12-27 11:12:50.347423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:12:50.348182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-12-27 11:12:50.357337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-12-27 11:12:50.490707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-12-27 11:12:50.559447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-12-27 11:12:50.578167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-12-27 11:12:50.713958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-12-27 11:12:50.806793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-12-27 11:12:51.138753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-12-27 11:12:51.139006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:12:51.140170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:12:51.140954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-12-27 11:12:51.143957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-12-27 11:12:51.145631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-12-27 11:12:51.145669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-12-27 11:12:51.145688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-12-27 11:12:51.147081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:12:51.147973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-27 11:12:51.148714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-12-27 11:12:51,150 - INFO - Log directory: data/model/pretrained/METR-LA\n",
            "WARNING:tensorflow:From /content/DCRNN/model/dcrnn_supervisor.py:35: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "2021-12-27 11:12:51,151 - INFO - {'base_dir': 'data/model', 'log_level': 'INFO', 'data': {'batch_size': 64, 'dataset_dir': 'data/METR-LA', 'graph_pkl_filename': 'data/sensor_graph/adj_mx.pkl', 'test_batch_size': 64}, 'model': {'cl_decay_steps': 2000, 'filter_type': 'dual_random_walk', 'horizon': 12, 'input_dim': 2, 'l1_decay': 0, 'max_diffusion_step': 2, 'num_nodes': 207, 'num_rnn_layers': 2, 'output_dim': 1, 'rnn_units': 64, 'seq_len': 12, 'use_curriculum_learning': True}, 'train': {'base_lr': 0.01, 'dropout': 0, 'epoch': 64, 'epochs': 100, 'epsilon': 0.001, 'global_step': 24375, 'log_dir': 'data/model/pretrained/METR-LA', 'lr_decay_ratio': 0.1, 'max_grad_norm': 5, 'max_to_keep': 100, 'min_learning_rate': 2e-06, 'model_filename': 'data/model/pretrained/METR-LA/models-2.7422-24375', 'optimizer': 'adam', 'patience': 50, 'steps': [20, 30, 40, 50], 'test_every_n_epochs': 10}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PEMS-BAY\n",
        "!python run_demo.py --config_filename=data/model/pretrained/PEMS-BAY/config.yaml\n",
        "#The generated prediction of DCRNN is in data/results/dcrnn_predictions."
      ],
      "metadata": {
        "id": "XUSTBsvQl5eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SJybBDWcM8G"
      },
      "source": [
        "Or retrain the model completely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3RKvlPecRCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c01ee5-b4ad-4d7a-8f14-9947854828ab"
      },
      "source": [
        "# METR-LA\n",
        "!python dcrnn_train.py --config_filename=data/model/dcrnn_la.yaml\n",
        "\n",
        "# PEMS-BAY\n",
        "!python dcrnn_train.py --config_filename=data/model/dcrnn_bay.yaml"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"dcrnn_train.py\", line 10, in <module>\n",
            "    from model.dcrnn_supervisor import DCRNNSupervisor\n",
            "  File \"/content/DCRNN/model/dcrnn_supervisor.py\", line 16, in <module>\n",
            "    from model.dcrnn_model import DCRNNModel\n",
            "  File \"/content/DCRNN/model/dcrnn_model.py\", line 7, in <module>\n",
            "    from tensorflow.contrib import legacy_seq2seq\n",
            "ModuleNotFoundError: No module named 'tensorflow.contrib'\n",
            "Traceback (most recent call last):\n",
            "  File \"dcrnn_train.py\", line 10, in <module>\n",
            "    from model.dcrnn_supervisor import DCRNNSupervisor\n",
            "  File \"/content/DCRNN/model/dcrnn_supervisor.py\", line 16, in <module>\n",
            "    from model.dcrnn_model import DCRNNModel\n",
            "  File \"/content/DCRNN/model/dcrnn_model.py\", line 7, in <module>\n",
            "    from tensorflow.contrib import legacy_seq2seq\n",
            "ModuleNotFoundError: No module named 'tensorflow.contrib'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeRyGzjdchZh"
      },
      "source": [
        "Eval Baseline Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKzLUzKOcjVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d279033b-b092-49cb-a6ed-a6b882b4ffe7"
      },
      "source": [
        "# METR-LA\n",
        "!python -m scripts.eval_baseline_methods --traffic_reading_filename=data/metr-la.h5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "2021-12-27 11:03:24,786 - INFO - Log directory: data/model\n",
            "2021-12-27 11:03:25,064 - INFO - Static\n",
            "2021-12-27 11:03:25,064 - INFO - Model\tHorizon\tRMSE\tMAPE\tMAE\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/DCRNN/scripts/eval_baseline_methods.py\", line 141, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DCRNN/scripts/eval_baseline_methods.py\", line 130, in main\n",
            "    eval_static(traffic_reading_df)\n",
            "  File \"/content/DCRNN/scripts/eval_baseline_methods.py\", line 95, in eval_static\n",
            "    rmse = masked_rmse_np(preds=y_predict.as_matrix(), labels=y_test.as_matrix(), null_val=0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\", line 5141, in __getattr__\n",
            "    return object.__getattribute__(self, name)\n",
            "AttributeError: 'DataFrame' object has no attribute 'as_matrix'\n"
          ]
        }
      ]
    }
  ]
}