{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AGCRN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import git hub: both of the github repos share the same dataset"
      ],
      "metadata": {
        "id": "--WGjs46okz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXW6fVTcoc55",
        "outputId": "71abd9fa-06d1-457d-e786-e9970a1c1842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AGCRN' already exists and is not an empty directory.\n",
            "fatal: destination path 'ASTGCN' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LeiBAI/AGCRN.git\n",
        "!git clone https://github.com/Davidham3/ASTGCN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AGCRN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYAHx8tBon8G",
        "outputId": "118a5700-a98c-4b36-dc69-46d688e2edb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AGCRN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries"
      ],
      "metadata": {
        "id": "NnM8nx2MpEhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install argparse\n",
        "!pip install configparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "OU6uyNKLpGpG",
        "outputId": "8610df6f-c34c-47e1-a9e8-c15fa2cdf351"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting argparse\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open the file explorer tab to the left. In the ASTGCN data folder, move everything out into the AGCRN data folder. Then, we are ready to run codes"
      ],
      "metadata": {
        "id": "CikN35W7pkkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91oDffz4qOn5",
        "outputId": "4c666e97-2467-4020-e47e-77a6e03a5225"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AGCRN/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you run the model, open the dataload.py file in \"lib\" subfolder and add this snippet to the 7th and the 10th line respectvely.\n",
        "\n",
        "\n",
        "```\n",
        "# /content/AGCRN/data/PEMS04/pems04.npz\n",
        "# /content/AGCRN/data/PEMS08/pems08.npz\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dEXWMamYTucu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To force training despite the value error, chage the last line in the \"Run.py\" file to\n",
        "\n",
        "\n",
        "```\n",
        "# trainer.train()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "wPgSvpxJVuhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python Run.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxXnJGlnqe_G",
        "outputId": "d06969c4-9416-455b-e166-729d8287cbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AGCRN\n",
            "*****************Model Parameter*****************\n",
            "node_embeddings torch.Size([307, 10]) True\n",
            "encoder.dcrnn_cells.0.gate.weights_pool torch.Size([10, 2, 65, 128]) True\n",
            "encoder.dcrnn_cells.0.gate.bias_pool torch.Size([10, 128]) True\n",
            "encoder.dcrnn_cells.0.update.weights_pool torch.Size([10, 2, 65, 64]) True\n",
            "encoder.dcrnn_cells.0.update.bias_pool torch.Size([10, 64]) True\n",
            "encoder.dcrnn_cells.1.gate.weights_pool torch.Size([10, 2, 128, 128]) True\n",
            "encoder.dcrnn_cells.1.gate.bias_pool torch.Size([10, 128]) True\n",
            "encoder.dcrnn_cells.1.update.weights_pool torch.Size([10, 2, 128, 64]) True\n",
            "encoder.dcrnn_cells.1.update.bias_pool torch.Size([10, 64]) True\n",
            "end_conv.weight torch.Size([12, 1, 1, 64]) True\n",
            "end_conv.bias torch.Size([12]) True\n",
            "Total params num: 748810\n",
            "*****************Finish Parameter****************\n",
            "Load PEMSD4 Dataset shaped:  (16992, 307, 1) 919.0 0.0 211.7007794815878 180.0\n",
            "Normalize the dataset by Standard Normalization\n",
            "Train:  (10173, 12, 307, 1) (10173, 12, 307, 1)\n",
            "Val:  (3375, 12, 307, 1) (3375, 12, 307, 1)\n",
            "Test:  (3375, 12, 307, 1) (3375, 12, 307, 1)\n",
            "2021-12-28 09:19: Experiment log path in: /content/AGCRN/model/experiments/PEMSD4/20211228091953\n",
            "2021-12-28 09:19: Train Epoch 1: 0/158 Loss: 208.421188\n",
            "2021-12-28 09:20: Train Epoch 1: 20/158 Loss: 190.737823\n",
            "2021-12-28 09:20: Train Epoch 1: 40/158 Loss: 184.127762\n",
            "2021-12-28 09:20: Train Epoch 1: 60/158 Loss: 227.657272\n",
            "2021-12-28 09:20: Train Epoch 1: 80/158 Loss: 194.900482\n",
            "2021-12-28 09:21: Train Epoch 1: 100/158 Loss: 188.068710\n",
            "2021-12-28 09:21: Train Epoch 1: 120/158 Loss: 178.584457\n",
            "2021-12-28 09:21: Train Epoch 1: 140/158 Loss: 200.141190\n",
            "2021-12-28 09:21: **********Train Epoch 1: averaged Loss: 191.759135, tf_ratio: 1.000000\n",
            "2021-12-28 09:21: **********Val Epoch 1: average Loss: 192.307707\n",
            "2021-12-28 09:21: *********************************Current best model saved!\n",
            "2021-12-28 09:21: Train Epoch 2: 0/158 Loss: 180.644623\n",
            "2021-12-28 09:22: Train Epoch 2: 20/158 Loss: 188.958359\n",
            "2021-12-28 09:22: Train Epoch 2: 40/158 Loss: 168.880615\n",
            "2021-12-28 09:22: Train Epoch 2: 60/158 Loss: 187.366623\n",
            "2021-12-28 09:22: Train Epoch 2: 80/158 Loss: 168.522980\n",
            "2021-12-28 09:23: Train Epoch 2: 100/158 Loss: 183.920029\n",
            "2021-12-28 09:23: Train Epoch 2: 120/158 Loss: 166.760681\n",
            "2021-12-28 09:23: Train Epoch 2: 140/158 Loss: 148.270096\n",
            "2021-12-28 09:23: **********Train Epoch 2: averaged Loss: 168.182421, tf_ratio: 1.000000\n",
            "2021-12-28 09:23: **********Val Epoch 2: average Loss: 173.199245\n",
            "2021-12-28 09:23: *********************************Current best model saved!\n",
            "2021-12-28 09:23: Train Epoch 3: 0/158 Loss: 149.541702\n",
            "2021-12-28 09:24: Train Epoch 3: 20/158 Loss: 150.713898\n",
            "2021-12-28 09:24: Train Epoch 3: 40/158 Loss: 157.513626\n",
            "2021-12-28 09:24: Train Epoch 3: 60/158 Loss: 159.971329\n",
            "2021-12-28 09:24: Train Epoch 3: 80/158 Loss: 146.073227\n",
            "2021-12-28 09:24: Train Epoch 3: 100/158 Loss: 154.344635\n",
            "2021-12-28 09:25: Train Epoch 3: 120/158 Loss: 164.412964\n",
            "2021-12-28 09:25: Train Epoch 3: 140/158 Loss: 134.253265\n",
            "2021-12-28 09:25: **********Train Epoch 3: averaged Loss: 152.870111, tf_ratio: 1.000000\n",
            "2021-12-28 09:25: **********Val Epoch 3: average Loss: 159.784112\n",
            "2021-12-28 09:25: *********************************Current best model saved!\n",
            "2021-12-28 09:25: Train Epoch 4: 0/158 Loss: 133.787140\n",
            "2021-12-28 09:26: Train Epoch 4: 20/158 Loss: 144.262634\n",
            "2021-12-28 09:26: Train Epoch 4: 40/158 Loss: 141.824448\n",
            "2021-12-28 09:26: Train Epoch 4: 60/158 Loss: 147.840500\n",
            "2021-12-28 09:26: Train Epoch 4: 80/158 Loss: 127.481850\n",
            "2021-12-28 09:26: Train Epoch 4: 100/158 Loss: 130.443085\n",
            "2021-12-28 09:27: Train Epoch 4: 120/158 Loss: 147.930054\n",
            "2021-12-28 09:27: Train Epoch 4: 140/158 Loss: 147.012115\n",
            "2021-12-28 09:27: **********Train Epoch 4: averaged Loss: 142.754599, tf_ratio: 1.000000\n",
            "2021-12-28 09:27: **********Val Epoch 4: average Loss: 150.426679\n",
            "2021-12-28 09:27: *********************************Current best model saved!\n",
            "2021-12-28 09:27: Train Epoch 5: 0/158 Loss: 134.654434\n",
            "2021-12-28 09:27: Train Epoch 5: 20/158 Loss: 135.601471\n",
            "2021-12-28 09:28: Train Epoch 5: 40/158 Loss: 134.675827\n",
            "2021-12-28 09:28: Train Epoch 5: 60/158 Loss: 140.087753\n",
            "2021-12-28 09:28: Train Epoch 5: 80/158 Loss: 126.525291\n",
            "2021-12-28 09:28: Train Epoch 5: 100/158 Loss: 142.198257\n",
            "2021-12-28 09:29: Train Epoch 5: 120/158 Loss: 136.545609\n",
            "2021-12-28 09:29: Train Epoch 5: 140/158 Loss: 123.883507\n",
            "2021-12-28 09:29: **********Train Epoch 5: averaged Loss: 136.085613, tf_ratio: 1.000000\n",
            "2021-12-28 09:29: **********Val Epoch 5: average Loss: 144.149780\n",
            "2021-12-28 09:29: *********************************Current best model saved!\n",
            "2021-12-28 09:29: Train Epoch 6: 0/158 Loss: 134.737259\n",
            "2021-12-28 09:29: Train Epoch 6: 20/158 Loss: 130.196228\n",
            "2021-12-28 09:30: Train Epoch 6: 40/158 Loss: 129.844513\n",
            "2021-12-28 09:30: Train Epoch 6: 60/158 Loss: 133.436890\n",
            "2021-12-28 09:30: Train Epoch 6: 80/158 Loss: 136.991150\n",
            "2021-12-28 09:30: Train Epoch 6: 100/158 Loss: 130.514114\n",
            "2021-12-28 09:31: Train Epoch 6: 120/158 Loss: 123.244095\n",
            "2021-12-28 09:31: Train Epoch 6: 140/158 Loss: 126.357262\n",
            "2021-12-28 09:31: **********Train Epoch 6: averaged Loss: 131.884857, tf_ratio: 1.000000\n",
            "2021-12-28 09:31: **********Val Epoch 6: average Loss: 140.000853\n",
            "2021-12-28 09:31: *********************************Current best model saved!\n",
            "2021-12-28 09:31: Train Epoch 7: 0/158 Loss: 131.356613\n",
            "2021-12-28 09:31: Train Epoch 7: 20/158 Loss: 125.485985\n",
            "2021-12-28 09:32: Train Epoch 7: 40/158 Loss: 137.761398\n",
            "2021-12-28 09:32: Train Epoch 7: 60/158 Loss: 131.638016\n",
            "2021-12-28 09:32: Train Epoch 7: 80/158 Loss: 130.205841\n",
            "2021-12-28 09:32: Train Epoch 7: 100/158 Loss: 124.057304\n",
            "2021-12-28 09:32: Train Epoch 7: 120/158 Loss: 127.518211\n",
            "2021-12-28 09:33: Train Epoch 7: 140/158 Loss: 127.252571\n",
            "2021-12-28 09:33: **********Train Epoch 7: averaged Loss: 129.323815, tf_ratio: 1.000000\n",
            "2021-12-28 09:33: **********Val Epoch 7: average Loss: 137.248197\n",
            "2021-12-28 09:33: *********************************Current best model saved!\n",
            "2021-12-28 09:33: Train Epoch 8: 0/158 Loss: 134.293152\n",
            "2021-12-28 09:33: Train Epoch 8: 20/158 Loss: 133.289459\n",
            "2021-12-28 09:34: Train Epoch 8: 40/158 Loss: 140.106964\n",
            "2021-12-28 09:34: Train Epoch 8: 60/158 Loss: 129.236710\n",
            "2021-12-28 09:34: Train Epoch 8: 80/158 Loss: 127.045380\n",
            "2021-12-28 09:34: Train Epoch 8: 100/158 Loss: 130.239609\n",
            "2021-12-28 09:34: Train Epoch 8: 120/158 Loss: 119.285393\n",
            "2021-12-28 09:35: Train Epoch 8: 140/158 Loss: 135.305588\n",
            "2021-12-28 09:35: **********Train Epoch 8: averaged Loss: 127.790565, tf_ratio: 1.000000\n",
            "2021-12-28 09:35: **********Val Epoch 8: average Loss: 135.452120\n",
            "2021-12-28 09:35: *********************************Current best model saved!\n",
            "2021-12-28 09:35: Train Epoch 9: 0/158 Loss: 129.077972\n",
            "2021-12-28 09:35: Train Epoch 9: 20/158 Loss: 127.845932\n",
            "2021-12-28 09:35: Train Epoch 9: 40/158 Loss: 122.621620\n",
            "2021-12-28 09:36: Train Epoch 9: 60/158 Loss: 121.840981\n",
            "2021-12-28 09:36: Train Epoch 9: 80/158 Loss: 123.020729\n",
            "2021-12-28 09:36: Train Epoch 9: 100/158 Loss: 126.833519\n",
            "2021-12-28 09:36: Train Epoch 9: 120/158 Loss: 133.297318\n",
            "2021-12-28 09:37: Train Epoch 9: 140/158 Loss: 123.865540\n",
            "2021-12-28 09:37: **********Train Epoch 9: averaged Loss: 127.045419, tf_ratio: 1.000000\n",
            "2021-12-28 09:37: **********Val Epoch 9: average Loss: 134.454587\n",
            "2021-12-28 09:37: *********************************Current best model saved!\n",
            "2021-12-28 09:37: Train Epoch 10: 0/158 Loss: 128.769760\n",
            "2021-12-28 09:37: Train Epoch 10: 20/158 Loss: 121.697121\n",
            "2021-12-28 09:37: Train Epoch 10: 40/158 Loss: 134.099579\n",
            "2021-12-28 09:38: Train Epoch 10: 60/158 Loss: 116.066086\n",
            "2021-12-28 09:38: Train Epoch 10: 80/158 Loss: 86.904480\n",
            "2021-12-28 09:38: Train Epoch 10: 100/158 Loss: 92.860298\n",
            "2021-12-28 09:38: Train Epoch 10: 120/158 Loss: 84.355919\n",
            "2021-12-28 09:39: Train Epoch 10: 140/158 Loss: 100.657852\n",
            "2021-12-28 09:39: **********Train Epoch 10: averaged Loss: 105.325476, tf_ratio: 1.000000\n",
            "2021-12-28 09:39: **********Val Epoch 10: average Loss: 92.538940\n",
            "2021-12-28 09:39: *********************************Current best model saved!\n",
            "2021-12-28 09:39: Train Epoch 11: 0/158 Loss: 80.724541\n",
            "2021-12-28 09:39: Train Epoch 11: 20/158 Loss: 86.357368\n",
            "2021-12-28 09:39: Train Epoch 11: 40/158 Loss: 73.604271\n",
            "2021-12-28 09:40: Train Epoch 11: 60/158 Loss: 74.766937\n",
            "2021-12-28 09:40: Train Epoch 11: 80/158 Loss: 83.171745\n",
            "2021-12-28 09:40: Train Epoch 11: 100/158 Loss: 72.874641\n",
            "2021-12-28 09:40: Train Epoch 11: 120/158 Loss: 64.260376\n",
            "2021-12-28 09:41: Train Epoch 11: 140/158 Loss: 71.688011\n",
            "2021-12-28 09:41: **********Train Epoch 11: averaged Loss: 75.359884, tf_ratio: 1.000000\n",
            "2021-12-28 09:41: **********Val Epoch 11: average Loss: 77.718169\n",
            "2021-12-28 09:41: *********************************Current best model saved!\n",
            "2021-12-28 09:41: Train Epoch 12: 0/158 Loss: 73.683891\n",
            "2021-12-28 09:41: Train Epoch 12: 20/158 Loss: 85.005386\n",
            "2021-12-28 09:41: Train Epoch 12: 40/158 Loss: 70.772247\n",
            "2021-12-28 09:42: Train Epoch 12: 60/158 Loss: 69.388878\n",
            "2021-12-28 09:42: Train Epoch 12: 80/158 Loss: 66.516663\n",
            "2021-12-28 09:42: Train Epoch 12: 100/158 Loss: 64.118294\n",
            "2021-12-28 09:42: Train Epoch 12: 120/158 Loss: 68.915588\n",
            "2021-12-28 09:43: Train Epoch 12: 140/158 Loss: 52.906055\n",
            "2021-12-28 09:43: **********Train Epoch 12: averaged Loss: 64.406185, tf_ratio: 1.000000\n",
            "2021-12-28 09:43: **********Val Epoch 12: average Loss: 67.382037\n",
            "2021-12-28 09:43: *********************************Current best model saved!\n",
            "2021-12-28 09:43: Train Epoch 13: 0/158 Loss: 57.505089\n",
            "2021-12-28 09:43: Train Epoch 13: 20/158 Loss: 62.944839\n",
            "2021-12-28 09:43: Train Epoch 13: 40/158 Loss: 59.976273\n",
            "2021-12-28 09:44: Train Epoch 13: 60/158 Loss: 57.969227\n",
            "2021-12-28 09:44: Train Epoch 13: 80/158 Loss: 54.096691\n",
            "2021-12-28 09:44: Train Epoch 13: 100/158 Loss: 60.451023\n",
            "2021-12-28 09:44: Train Epoch 13: 120/158 Loss: 57.778610\n",
            "2021-12-28 09:45: Train Epoch 13: 140/158 Loss: 55.307549\n",
            "2021-12-28 09:45: **********Train Epoch 13: averaged Loss: 56.180249, tf_ratio: 1.000000\n",
            "2021-12-28 09:45: **********Val Epoch 13: average Loss: 59.315458\n",
            "2021-12-28 09:45: *********************************Current best model saved!\n",
            "2021-12-28 09:45: Train Epoch 14: 0/158 Loss: 57.202450\n",
            "2021-12-28 09:45: Train Epoch 14: 20/158 Loss: 53.233700\n",
            "2021-12-28 09:45: Train Epoch 14: 40/158 Loss: 48.842777\n",
            "2021-12-28 09:46: Train Epoch 14: 60/158 Loss: 48.064987\n",
            "2021-12-28 09:46: Train Epoch 14: 80/158 Loss: 42.525017\n",
            "2021-12-28 09:46: Train Epoch 14: 100/158 Loss: 50.520107\n",
            "2021-12-28 09:46: Train Epoch 14: 120/158 Loss: 50.943554\n"
          ]
        }
      ]
    }
  ]
}